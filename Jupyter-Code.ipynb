{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cf7bdc",
   "metadata": {},
   "source": [
    "This code is manually written to test the components of the chatbot.py file \n",
    "For the full use of project refer the chatbot.py file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61c9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings,ChatHuggingFace\n",
    "from youtube_transcript_api import YouTubeTranscriptApi,TranscriptsDisabled\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import streamlit\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "HUGGINGFACE_API_TOKEN=os.getenv('HUGGINGFACE_API_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da058db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'Hindi (auto-generated)')]\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=uahX_JSdA2Q\"\n",
    "\n",
    "\n",
    "def extract_video_id(url):\n",
    "    if \"v=\" in url:\n",
    "        return url.split(\"v=\")[1].split(\"&\")[0]\n",
    "    elif \"youtu.be/\" in url:\n",
    "        return url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "# === ðŸ“˜ Get all transcript languages ===\n",
    "def get_available_languages(video_id):\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        return [(t.language_code, t.language) for t in transcript_list]\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "print(get_available_languages(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51881f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f1bb1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uahX_JSdA2Q\n",
      "[('hi', 'Hindi (auto-generated)')]\n"
     ]
    }
   ],
   "source": [
    "video_id=extract_video_id(url=url)\n",
    "print(video_id)\n",
    "\n",
    "languages=get_available_languages(video_id=video_id)\n",
    "print(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97de348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7562b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcription(video_id, lang_code=\"en\"):\n",
    "    \"\"\"\n",
    "    Safely fetches transcript text (manual or auto-generated) for a given video ID and language code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "\n",
    "        selected_transcript = None\n",
    "\n",
    "        for t in transcript_list:\n",
    "            if t.language_code == lang_code:\n",
    "                selected_transcript = t\n",
    "                break\n",
    "\n",
    "        if not selected_transcript:\n",
    "            return None\n",
    "\n",
    "        # âœ… Correct way to access the text\n",
    "        transcript_data = selected_transcript.fetch()\n",
    "        return \" \".join(chunk.text for chunk in transcript_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Transcript fetch error:\", e)\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1037357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(transcript):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "    chunks = splitter.create_documents([transcript])\n",
    "    # chunks\n",
    "    return chunks\n",
    "\n",
    "chunks=create_chunks(transcript)\n",
    "# print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d12af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeetu\\OneDrive\\Desktop\\LANGCHAIN\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# defining the embedding model\n",
    "embedding_model=HuggingFaceEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
    "\n",
    "# we can save locally using\n",
    "# vector_store.save_local('vectostore/db_faiss')\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "# response=retriever.invoke(\"What is Self Attention\")\n",
    "# print(response)\n",
    "\n",
    "# designing the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fc42baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=input(\"Enter the Query : \")\n",
    "# context--> they are the retrieved documenst from the vectorstore through the similarity search\n",
    "\n",
    "context_docs=retriever.invoke(user_query)\n",
    "\n",
    "context_text = \"\\n\\n\".join(doc.page_content for doc in context_docs)\n",
    "context_text\n",
    "\n",
    "# context_text\n",
    "def format_docs(context_text):\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "745fca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the llm model using the ChatHuggingFace mistral model\n",
    "def load_llm():\n",
    "    llm=HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text generation\",\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_TOKEN )\n",
    "\n",
    "    llm=ChatHuggingFace(llm=llm)\n",
    "\n",
    "    return llm\n",
    "\n",
    "# final_response=llm.invoke(final_prompt)\n",
    "# print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ecfbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f66a663d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The provided context suggests that transformers are a significant invention in the field of AI, leading to a current boom in AI. They are a specific kind of neural network, a machine learning model, and are used to build various models, including those that take in audio and produce a transcript, or those that take in text and produce images (like DALL-E and Midjourney). However, the context does not directly explain how transformers specifically effect the AI field, but rather that they are a key component contributing to advancements in AI.\n"
     ]
    }
   ],
   "source": [
    "llm=load_llm()\n",
    "final_chain=parallel_chain|prompt|llm|parser\n",
    "response=final_chain.invoke(user_query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbd010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1c0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f331e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecf263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53006dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
